---
title: "Clase 9"
subtitle: "Modelos mixtos"
author: "Miriam Lerma"
date: "Mayo 2021"
output:
  xaringan::moon_reader:
    css: RZero-themer2.css
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      
---

```{r metathis, include = FALSE}
#Con esta libreria puedo poner informacion que saldra en el titulo, en los buscadores y demas, como de titulo y fechas. Asi como elegir la imagen que saldra de inicio.

library(metathis)
meta() %>%
  meta_name("github-repo" = "MiriamLL/Curso_CIAD") %>%
  meta_social(
    title = "Cargar datps",
    description = paste0(
      "Introduccion a RStudio",
      "Curso de R"),
    url = "https://github.com/MiriamLL/Curso_CIAD/blob/main/Clase3Parte1.html",
    image_alt = paste0(
      "Introduccion a R y RStudio",
      "Curso de R"),
    og_type = "website",
    og_author = "Miriam Lerma",
    twitter_card_type = "summary_large_image",
    twitter_creator = "@MiriamLL",
    twitter_site = "@MiriamLL")
```

```{r include = FALSE}
#Paquetes
library(xaringanExtra)
ColorLink<-"#e63946"
ColorLinkInv<-"#f2cc8f"
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
``` 

```{r, echo=FALSE,include=FALSE, message=FALSE}
library(emo)
library(here)
library(fontawesome)
library(ggplot2)
#library(countdown)
#countdown(minutes = 5, seconds = 00, play_sound = TRUE,right = "33%")
```

class: title-slide, inverse, middle, right
background-image: url(https://images.unsplash.com/photo-1602264419088-8f8c7ab48489?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1267&q=80)
background-size: cover

<h3>`r rmarkdown::metadata$title`</h3>
<h1> `r rmarkdown::metadata$subtitle`</h1>

<h2> `r rmarkdown::metadata$author`</h2><br>
`r rmarkdown::metadata$date`

---

class: inverse

# Intro
- [Modelos mixtos](#modelos_mixtos)
- [AIC](#AIC)

--

#### Ustedes

- Conocimientos de R (saben abrirlo, cargar paquetes y datos, saben hacer operaciones y gr√°ficos).  
- Quieren crear modelos mixtos en R y conocer la sintaxis.  
La clase de hoy esta en el [repositorio](https://github.com/MiriamLL/Prueba):
Clonen/Descarguen los materiales.  

#### Preguntas
Responder en el chat üí¨
- Han visto modelos mixtos en art√≠culos o tesis?
- Alguien ha escuchado que es el AIC?

---
class: inverse

## Cr√©ditos & Recursos

Lecturas
- [`r fa("book-open", fill = ColorLinkInv)` Intro por Gabriela Hajduk](https://gkhajduk.github.io/2017-03-09-mixed-models/)
- [`r fa("book-open", fill = ColorLinkInv)` Introduccion por Athanasia Mowinckel](https://athanasiamo.github.io/LME_introduction_workshop/slides/lme_rladies_london.html#1)<br>
- [`r fa("book-open", fill = ColorLinkInv)` Lectura sobre mixed-models with R Michel Clark](https://m-clark.github.io/mixed-models-with-R/#)

Videos en espa√±ol
- [`r fa("youtube", fill = ColorLinkInv)` Modelos mixtos por Alejandra Tapia](https://alejandraandrea.github.io/slides-xaringan-mixed-models/#1)<br>


Imagenes
- Portada  
[Unsplash by Ilse Orsel](https://unsplash.com/@lgtts)  


---

class: title-slide, center, middle, inverse

# 1. Modelos lineares mixtos

---

## 1.1. Intro

**Modelos lineales**:  
- Errores aleatorios independientes
- Errores aleatorios siguen una distribuci√≥n normal

**Modelos lineales mixtos**
- Incorpora efectos aleatorios para acomodar la correlaci√≥n entre las observaciones 
- Condicionado a los efectos aleatorios, los errores aleatorios son independientes con  varianza constante 
- Errores aleatorios con distribuci√≥n normal
- Efectos aleatorios con distribuci√≥n normal 
- Efectos aleatorios y errores aleatorios son independientes 


** ¬øPorque usarlos?**

- Datos pueden presentar heterogeneidad
- Por ejemplo: pueden estar agrupados por provenir de diferentes √°reas, o presentar medidas repetidas
- Medidas repetidas induce a una estructura de correlaci√≥n, que si no se considera puede llevar a estimaciones sesgadas
- Afectando las predicciones y por lo tanto las decisiones basadas en esos datos


---
name: lmer

## 1.2. Datos

Paquetes a cargar para leer los datos
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(here)
```

Cargar datos
```{r, message=FALSE}
url <- "https://raw.githubusercontent.com/MiriamLL/Prueba/master/dragones.csv"
download.file(url, "dragons.csv")
dragones <- read_csv("dragons.csv") 
```
**Nota** Estos datos son repetidamente utilizados para ense√±ar modelos mixtos. Entonces pueden encontrar estos ejemplos explicados de diferente manera en linea f√°cilmente.

---

## 1.2. Datos

Los datos contienen 480 observaciones contenidas en 4 columnas: calificaci√≥n, tama√±o, monta√±a, sitio.
```{r}
glimpse(dragones)
```


---

## 1.3. Preguntas

Imaginemos que:  
Se entrenaron dragones y se recopilaron datos de diferentes monta√±as.

.center[<h1>üêâüí°</h1>]  

Entre mas r√°pido aprendieron el entrenamiento mejor calificaci√≥n, tambi√©n se midieron y se anot√≥ en que sitio y en que regi√≥n provienen.

.center[<h1>üê≤üíØ</h1>] 

<h3>¬øAfectar√° el tama√±o de los dragones sus calificaciones?</h3>


---

## 1.4. Inspeccionar datos

Creemos un gr√°fico de puntos
```{r,out.width="40%"}
dragones %>% 
  ggplot(aes(x=tamanio, 
             y=calificacion)) + 
             geom_jitter(alpha=.2)+
             theme_bw()
```


---

## 1.5 Modelo lineal

Cargar paquetes
```{r}
library(broom)
```

Ajustar un modelo lineal
```{r}
ajuste_lm <- lm(calificacion ~ tamanio, data=dragones)
```

Mirar estad√≠sticos del modelo
```{r}
broom::tidy(ajuste_lm) %>% tibble::as_tibble()
```
**¬øEntre m√°s grandes, m√°s inteligentes?** ü§î

---

## 1.5 Modelo lineal

Informaci√≥n sobre el modelo.
```{r, eval=FALSE}
glance(ajuste_lm) %>% 
  tibble::as_tibble()
```
Informaci√≥n sobre el ajuste del modelo. Esta funci√≥n agrega los valores ajustados, los residuales y otros al data frame.

```{r}
info_ajuste_lm<-augment_columns(ajuste_lm, dragones)
info_ajuste_lm
```

---

## 1.5 Modelo lineal

Gr√°ficar el modelo lineal.
```{r,out.width="40%"}
info_ajuste_lm %>% 
  ggplot(aes(x=tamanio,y=calificacion))+ 
  geom_jitter(alpha=.2)+
  geom_line(aes(x=tamanio,y=.fitted))+
  theme_bw()
```

---

## 1.6. Supuestos

Problemas de linealidad, media no es cero, varianza no es constante.
```{r,out.width="40%"}
plot(ajuste_lm, which=1)
```

---

## 1.6. Supuestos

Normalidad
```{r,out.width="40%"}
plot(ajuste_lm, which=2)
```

---

## 1.6. Supuestos
Homoscedasticidad
```{r,out.width="40%"}
plot(ajuste_lm, which=3)
```

---

## 1.7. Inspeccionar

Al graficar las monta√±as por separado. ¬øQue notan?

.pull-left[
```{r plotmontania4, eval=FALSE}
dragones %>%
  ggplot(aes(x=tamanio,y=calificacion, 
        colour=montania)) +
  geom_jitter(alpha=2) +
  theme_bw()
```
]

.pull-right[
```{r plotmontania4, ref.label='plotmontania4', warning=FALSE,echo=FALSE, out.width="80%"}
```
]

---

## 1.8. Inspeccionar

Separando por monta√±as. ¬øQue notan?

.pull-left[
```{r plotmontania3, eval=FALSE}
dragones %>% 
  ggplot(aes(tamanio,calificacion,
      colour = montania))+
  geom_jitter(alpha=2) + 
  facet_wrap(~ montania) +
  theme_bw()+
  theme(strip.background=element_rect(fill="white"))
```
]

.pull-right[
```{r plotmontania3, ref.label='plotmontania3', warning=FALSE,echo=FALSE, out.width="80%"}
```
]

---
name: modelos_mixtos

## 1.9. Efectos aleatorios

No se puede omitir la monta√±a , ¬øpero como la incluimos?

--

- Como factor aleatorio.
- [`r fa("external-link-alt", fill = ColorLink)` Que es un factor aleatorio y como saber cuando es aleatorio](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)

--

Paquetes
```{r, message=FALSE, warning=FALSE}
library(broom.mixed)
library(lme4)
```

Sintaxis de los efectos aleatorios (random effects):
```{r}
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
```

**Nota** Que se llamen efectos aleatorios poco tiene que ver con que aleatoriedad matem√°tica. Es confuso pero por ahora lo m√°s sencillo es pensar en ellos como variables de [agrupamiento](https://gkhajduk.github.io/2017-03-09-mixed-models/). 


---

## 1.9. Efectos aleatorios

Mirar nuestro nuevo modelo.
```{r}
tidy(ajuste_lmer) %>% 
  tibble::as_tibble()
```

---

## 1.9. Efectos aleatorios

Mirar los ajustes del modelo.
```{r}
glance(ajuste_lmer) %>% 
  tibble::as_tibble()
```

<h3>¬øNo hay valor p? üíîüò≠</h3>

<br>

Lecturas sobre valor _p_ :
- Explicaci√≥n por parte del desarrollador del paquete lmer: [Douglas Bates](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html)
- Compilaci√≥n de recursos sobre el valor *p* por [Rocio Joo](https://rociojoo.github.io/Curso-R-biologging/04-Modelos-Mixtos.html#55)



---

## 1.9. Valor p

A pesar de que no se recomienda usar valor p, la librer√≠a lmerTest te puede dar un valor p. 

Considera que: *all the F ratios use the same denominator* - [Douglas Bates](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html)

```{r,message=FALSE, warning=FALSE}
library(lmerTest)
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
tidy(ajuste_lmer) %>% 
  tibble::as_tibble()
```

---

## 1.10. Efecto de la monta√±a

Ver informaci√≥n del ajuste: valores ajustados (.fitted), residuales (.resid)
**augment_columns** agrega los valores ajustados, los residuales y otros al data frame.
```{r}
info_ajuste_lmer<- augment_columns(ajuste_lmer,dragones)
info_ajuste_lmer
```


---

## 1.10. Efecto de la monta√±a

Veamos el efecto de las monta√±as en la calificaci√≥n.
.pull-left[
```{r plotmontania, eval=FALSE}
info_ajuste_lmer %>% 
 ggplot(aes(x=tamanio,y=calificacion, 
            colour=montania))+ 
 geom_jitter(alpha=2)+ 
 facet_wrap(~ montania)+
 geom_line(aes(x=tamanio,
               y=.fitted),
 colour="black")+
theme_bw()
```
]

.pull-right[
```{r plotmontania, ref.label='plotmontania', warning=FALSE,echo=FALSE, out.width="80%"}
```
]

---

## 1.11. Supuestos

Al incluir monta√±a en el modelo, no se observan problema se linealidad, la media y varianza son constantes.
```{r,out.width="30%"}
plot(ajuste_lmer)
```

---

## 1.11. Supuestos
Al incluir monta√±a en el modelo, no se ven problemas en los residuales del modelo. 
```{r,out.width="30%"}
qqnorm(resid(ajuste_lmer))
qqline(resid(ajuste_lmer))
```

---

## 1.11. Modelo mixto

Ver ajustes del modelo mixto que incluye **monta√±as**

Se ve que la varianza de el sistema monta√±oso es 339.7.
Entonces las monta√±as son claramente importantes porque explican mucha de la variaci√≥n. Como saber cuanto explican de la variaci√≥n? Se puede tomar la varianza de la monta√±a y dividirla por el total de la varianza. 

```{r,eval=FALSE}
summary(ajuste_lmer)
```

```{r}
339.7/(339.7 + 223.8)
```

Otro valor interesante es el AIC. Hablaremos m√°s adeltante de esto.
```{r}
AIC(ajuste_lmer)
```

---

## 2.1. Modelo completo

Al incluir monta√±a nos hemos dado cuenta que es importante incluirla, ¬øsera importante incluir sitio tambi√©n?  
Lo que nos lleva a preguntarnos, con los datos que tenemos como sabemos:  
¬øQue modelo se ajusta mejor a nuestros datos?  

.center[<h1>üêâüí°</h1>]  

---

## 2.1. Efectos aleatorios anidados

En nuestros datos de dragones: la variable de **sitio** es un factor con tres niveles: un sitio a, b y c, pero existe un anidamiento (nesting) del sitio con la monta√±a. Los sitios no tienen significado si no le asignamos las monta√±as. 

Para no tener que estar recordando que esto ocurre, lo mejor es crear una nueva variable anidada (nested).

```{r}
dragones$muestra <- factor(paste0(dragones$montania,
                                  dragones$sitio))
```

---

## 2.2. Efectos aleatorios cruzados

De acuerdo a lo que vimos anteriormente, entonces no podemos poner los efectos aleatorios separados.
```{r}
modelo_incorrecto <- lmer(calificacion ~ tamanio + 
                      (1|montania) + (1|sitio), data = dragones)  
```
Este modelo trata los efectos aleatorios como **cruzados**.

Para efectos cruzados es cuando el factor aparece en m√°s de un nivel en otros factores, un ejemplo seria si el mismo drag√≥n aparece en m√°s de un sistema monta√±oso.
 

---

## 2.3. Efectos aleatorios anidados

Con los datos de dragones, una manera de crear un modelo completo ser√≠a la siguiente.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + 
                        (1|montania) + (1|muestra), 
				  data = dragones)
```

```{r, eval=FALSE}
summary(lmer_completo)
```

Si buscan ejemplos otras maneras de escribir esto son:
```{r, eval=FALSE}
(1|montania/sitio) 
(1|montania) + (1|montania:sitio)
```

---

## 2.4. Modelo completo

Ahora que creamos un modelo considerando los efectos aleatorios, nos queda claro que el an√°lisis inicial (el modelo linear) nos daba resultados que **no eran correctos**, los dragones no son m√°s inteligentes entre m√°s grandes. 

En el futuro podemos elegir dragones m√°s peque√±os para entrenarlos.ü§† 

.pull-left[
```{r plotmontania2, eval=FALSE}
ggplot(dragones, aes(x = tamanio, y = calificacion, colour = sitio)) +
  facet_wrap(~montania, nrow=3) +
  geom_point() +
  theme_classic() +
  geom_line(data = cbind(dragones, pred = predict(lmer_completo)), aes(y = pred)) +
  theme(legend.position = "none")
```
]

.pull-right[
```{r plotmontania2, ref.label='plotmontania2', warning=FALSE,echo=FALSE, out.width="80%"}
```
]


---

name: AIC
class: title-slide,center, middle, inverse

# 3. AIC

---

## 3.1. AIC

El AIC (Akaike Information Criterion) es un modelo matem√°tico para evaluar que tan bien se ajusta el modelo a los datos generados. 

En estad√≠stica se usa mucho para comparar modelos posibles y determinar cual es el mejor modelo.

AIC se calcula a partir de:
- El numero de variables independientes que se us√≥ para construir el modelo
- El estimado de m√°xima verosimilitud (maximum likelihood), (que tan bien el modelo reproduce los datos)

```{r, echo=FALSE, out.height=50, fig.align='center'}
knitr::include_graphics("https://cdn.scribbr.com/wp-content/uploads/2020/03/aic_formula-300x57.png")
```
.right[Fuente: [Scribbr](https://www.scribbr.com/statistics/akaike-information-criterion/)]

K es el n√∫mero de variables independientes y L es el estimado de m√°xima verosimilitud. 

El mejor modelo se identifica a partir de un AIC, que explica la mayor cantidad de variaci√≥n usando el menor numero de variables independientes. 

---


## 3.1. AIC

Los AIC son muy usados para evaluar la combinaci√≥n completa de los predictores y el mejor modelo se considera el que tiene el menor valor de AIC

```{r, echo=FALSE, out.height=150, fig.align='center'}
knitr::include_graphics("https://cdn.scribbr.com/wp-content/uploads/2020/03/aic_model_output.png")
```
.right[Fuente: [Scribbr](https://www.scribbr.com/statistics/akaike-information-criterion/)]

- **K** es el numero de parametros del modelo. El default es 2, asi que cualquier modelo con un parametro dara una K de 2+1=3.
- **AICc ** es el calculo del AIC, la c viene de corregido para muestras peque√±as. Entre m√°s peque√±o el AIC mejor es el ajuste del modelo.
- **Delta AIC** es la diferencia entre los valores de AIC. Diferencias peque√±as (<2 unidades) no son consideradas significativas. Si varios modelos tienen menos de estas unidades, el mejor modelo es el que es m√°s parsimonioso, es decir el que tiene el menor numero de par√°metros
- **AICcWT**: es la proporci√≥n del total de poder predictivo dado por el set de modelos probados en el modelo. 

---

## 3.2. Selecci√≥n del modelo

De acuerdo a lo que vimos, es f√°cil omitir algunas variables pero tambi√©n podr√≠amos incluir algunas que no son importantes (lo que se conoce como [overfit](https://ourcodingclub.github.io/tutorials/modelling/)).  

Para resolver este problema lo que se hace es una **selecci√≥n del modelo**.  

Pero, hay que ser muy cuidadosos en lo que se refiere a la selecci√≥n del modelo.  
Para hacer una buena selecci√≥n hay que tener claro cual es la **pregunta**.  

En lo que respecta a biolog√≠a, se puede usar la selecci√≥n de modelos para revisar par√°metros que no corresponden al n√∫cleo de la pregunta. 

Tambi√©n se **recomienda** tener 10 veces m√°s datos que par√°metros.

- [Da click aqu√≠ para mirar algunas formulas y explicacion a detalle](https://bookdown.org/egarpor/PM-UC3M/lm-ii-modsel.html)

---

## 3.3. Selecci√≥n del modelo

De mejor a peor lo que podemos usar para comparar modelos son:

- Z-test de Wald 
- t-test de Wald (en este modelo los valores tendr√≠an que estar balanceados)
- **Prueba de raz√≥n de verosimilitud** (en ingl√©s: Likelihood ratio tests).  
Usando anova() o drop1())
- Markov chain Monte Carlo (MCMC) o un bootstramp par√°metrico con intervalos de confianza

---

## 3.4. Compara modelos

En nuestro ejemplo de dragones podemos comparar
- Modelo completo.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + #<<
                        (1|montania) + (1|muestra),
                      data = dragones, REML = FALSE)
```

- Modelo reducido. **Nota** que este modelo no incluye tama√±o.
```{r}
lmer_reducido <- lmer(calificacion ~ 1 + #<<
                        (1|montania) + (1|muestra), 
                      data = dragones, REML = FALSE)
```

Comparaci√≥n de los modelos. 
```{r, eval=FALSE}
anova(lmer_reducido, lmer_completo) 
```

---

## 3.5. Compara modelos

Al comparar los modelos encontramos que no son significativamente diferentes.  
Es decir, **tama√±o** no ayuda a explicar la calificaci√≥n de los dragones.
```{r}
anova(lmer_reducido, lmer_completo)  
```


---

## 3.6. Otro ejemplo

Veamos otro ejemplo.
```{r, message=FALSE, warning=FALSE}
library(readr)
```

Que pasa si tenemos tres modelos en mente a comparar.  
```{r, message=FALSE}
url <- "https://raw.githubusercontent.com/MiriamLL/Prueba/master/bmi_data.csv"
download.file(url, "bmi_data.csv")
bmi_datos <- read_csv("bmi_data.csv") 
```
.right[Fuente: [Scribbr](https://www.scribbr.com/statistics/akaike-information-criterion/)]

Estos datos de bebidas azucaradas, y contiene informaci√≥n de:
- Sexo (Female/Male)  
- Edad (n√∫merico)   üë∂üèΩüëßüèΩüë®üèΩ‚Äçü¶±üëµüèΩ
- Consumo (n√∫merico) üßÉü•§
- BMI (indice de masa corporal)

---

## 3.7. Construir modelos

Primer modelo
```{r}
mod_edad <- lm(bmi ~ age, data = bmi_datos)
```

Segundo modelo
```{r}
mod_sexo <- lm(bmi ~ sex, data = bmi_datos)
```

Tercer modelo
```{r}
mod_consumo <- lm(bmi ~ consumption, data = bmi_datos)
```

---

## 3.8. Usar AICmodavg

Comparar modelos
```{r, warning=FALSE, message=FALSE}
library(AICcmodavg)
```

```{r}
modelos <-list(mod_edad, mod_sexo, mod_consumo)
modelos_nombres<-c('mod_edad', 'mod_sexo', 'mod_consumo')
```

La edad parece ser de las variables m√°s importantes para explicar indice de masa corporal. 
```{r}
aictab(cand.set = modelos, modnames = modelos_nombres)
```

---

## 3.9. Comparar muchos modelos

Pero resulta evidente que habr√° que incluir la combinaci√≥n de sexo y edad.
```{r}
mod_sexo_edad <- lm(bmi ~ age + sex, data = bmi_datos)
```

Incluir la combinaci√≥n de sexo, edad y consumo de bebidas azucaradas.
```{r}
mod_combinacion <- lm(bmi ~ age + sex + consumption, data = bmi_datos)
```

Finalmente probar la interacci√≥n entre estas variables.
```{r}
mod_interaccion <- lm(bmi ~ age*sex*consumption, data = bmi_datos)
```

Con todos los modelos se puede crear una lista y un vector con los nombres de los modelos para poder identificarlos.

```{r}
modelos <-list(mod_edad, mod_sexo, mod_consumo, mod_sexo_edad, mod_combinacion, mod_interaccion)
modelos_nombres<-c('mod_edad', 'mod_sexo', 'mod_consumo','mod_sexo_edad', 'mod_combinacion', 'mod_interaccion')
```

---

## 3.9. Comparar muchos modelos

Responder en el chat üí¨
En base al AIC ¬øCual es el mejor modelo?
```{r}
aictab(cand.set = modelos, modnames = modelos_nombres)
```

--

```{r, eval=FALSE}
mod_combinacion <- lm(bmi ~ age + sex + consumption, data = bmi_datos)
```


---

## 3.10. MASS

Otra cosa que podemos hacer es pedirle a R que construya los modelos con base a la informaci√≥n que le damos.  
```{r}
bmi_mod_comp <- lm(bmi ~., data = bmi_datos)
```
**Nota** tu dataframe solo debe incluir las columnas de las variables que te interesa incluir.

Un paquete que tambien te permite comparar modelos es **MASS**. 
```{r, warning=FALSE, message=FALSE}
library(MASS)
```

La ventaja de este paquete es que la funci√≥n stepAIC te permite elegir: direction = c("both", "backward", "forward"). 
```{r}
step.model <- stepAIC(bmi_mod_comp, direction = "both", 
                      trace = FALSE)
```

- [Da click aqu√≠ la explicaci√≥n de Stepwise regression a detalle](http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/)

---

## 3.10. MASS

De entrada ya nos dice cual fue el mejor modelo. 

```{r}
summary(step.model)
```

---

## 3.11. drop1

Otra manera de comparar modelos es usando **drop1**

Igualmente se puede crear el modelo completo y la funci√≥n drop1 te da los resultados similares como reducir tu modelo.

Los resultados se pueden interpretar en que modelo sin el termino es significativamente diferente del modelo con tal termino. Y de nuevo ofrece un AIC que entre menor es el mejor modelo. 

```{r}
drop1(bmi_mod_comp, test="F") # Tambien llamado 'type II' anova
```

---

## 3.12. Usando dredge

La funci√≥n **dredge** del paquete MuMIN genera una tabla de selecci√≥n de modelos usando las combinaciones de los efectos fijos en el modelo global.
```{r, warnings=FALSE, message=FALSE}
library(MuMIn)
options(na.action = "na.fail")
```
- **AICc**: Valores AIC con correcci√≥n
- **delta**: diferencia entre modelos. Por convenci√≥n AIC<2 se consideran modelos aceptables.
- **weight**: Peso del modelo.

Todos estos valores pueden reportarse.

```{r, eval=FALSE}
dredge(bmi_mod_comp)
```

---

## 3.13. Usando dredge

Veamos con los datos de dragones.

```{r, eval=FALSE}
library(MuMIn)
options(na.action = "na.fail")
dragones$muestra <- factor(paste0(dragones$montania,
                                  dragones$sitio))
lmer_completo <- lmer(calificacion ~ tamanio +
                        (1|montania) + (1|muestra),
                      data = dragones,REML=FALSE)#<<
dredge(lmer_completo)
```

**Nota** REML es el restricted maximum likelihood.  
Cuando se prueba el modelo regularmente se pone REML=FALSE.  
Esto es para que pueda crear modelos m√°s sencillos a la hora de probar las combinaciones.  
Pero una vez sepamos cual es el mejor modelo, podemos poner de nuevo REML=TRUE para obtener los resultados.  

---

## 3.14. Usando dredge

El mejor modelo incluye todos los parametros.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio +
                        (1|montania) + (1|muestra),
                      data = dragones,REML=TRUE) #<<
```

Ver estimados del modelo.
```{r, eval=FALSE}
summary(lmer_completo)
```

Cuando m√°s de un modelo se encuentra dentro de las 2 unidades AIC, depende de tu criterio de selecci√≥n.  
Una opci√≥n es primero reportar que varios modelos estuvieron dentro de las dos unidades AIC, y que se usaron todos los par√°metros de los modelos con menos de 2 unidades AIC.


---

## 3.16. Usando dredge

Para reportar en la selecci√≥n del modelo.
```{r, eval=FALSE}
   (Intrc)   taman df    logLik   AICc delta weight
1   50.39          4 -1989.527 3987.1  0.00  0.706
2   39.09 0.05611  5 -1989.384 3988.9  1.76  0.294 
```

Para reportar en los estimados del modelo seleccionado.
```{r, eval=FALSE}
Fixed effects:
            Estimate Std. Error       df t value Pr(>|t|)  
(Intercept) 40.06668   21.86373 90.35454   1.833   0.0702 .
tamanio      0.05126    0.10368 94.18716   0.494   0.6222  
```

---


# 4. Seguir aprendiendo

En la p√°gina de [CRAN Task Viewer](https://cran.r-project.org/web/views/Environmetrics.html) pueden encontrar referencias de paquetes de acuerdo al modelo que quieran crear. 

- Base R provee: lm() y glm(). Ya usamos lm en la [clase modelos lineales simples](https://miriamll.github.io/Curso_CIAD/Clase7#38)

- **lme4** provee funciones para realizar modelos generalizados mixtos lineares o no lineares (GLMM). Usamos este paquete en esta clase. Si quieren ver tutoriales de como funciona les recomiendo [`r fa("youtube", fill = ColorLink)` Video explicando Teor√≠a: Kyle Tomlinson](https://www.youtube.com/watch?v=sdYKtsmtXmc&list=PLVlVXU7jGfm1seY4xxINrsp23AmrYFYa7&index=4).

- **nlme** provee funciones para realizar modelos lineares y no lineares con efectos mixtos (GLM)

- **mgvc** provee funciones para realizar modelos aditivos (Generalized Additive Mixed Models: GAMMS) [`r fa("youtube", fill = ColorLink)` gms introduction to generalized additive models with R and mgvc](https://www.youtube.com/watch?v=sgw4cu8hrZM)


#### Otros recursos

- [Usar Machine learning](https://github.com/m-clark/introduction-to-machine-learning)
- [Usar estadistica bayesiana](https://oliviergimenez.github.io/blog/bayesworkshop/)

---

class: title-slide, left, inverse

# Contacto

Recapitulando

- [Modelos mixtos](#modelos_mixtos)
- [AIC](#AIC)

<br>
<br>

Para dudas, comentarios y sugerencias:  
- Escr√≠beme a miriamjlerma@gmail.com

<br>
<br>

.right[Este material esta accesible y se encuentra en <br>
mi [`r fa("external-link-alt", fill = ColorLinkInv)`github](https://github.com/MiriamLL/Curso_CIAD/)
y mi [`r fa("external-link-alt", fill = ColorLinkInv)`p√°gina](https://www.miriam-lerma.com/posts/2021-03-01-introar/)


.center[
```{r, echo=FALSE}
library(fontawesome)
```
<h3>`r fa("home", fill = ColorLinkInv)`[Volver ](https://www.miriam-lerma.com/posts/2021-03-01-introar/)
]]

