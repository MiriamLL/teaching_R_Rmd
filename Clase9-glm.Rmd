---
title: "Clase 7"
subtitle: "Modelos mixtos"
author: "Miriam Lerma"
date: "Mayo 2021"
output:
  xaringan::moon_reader:
    css: RZero-themer.css
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      
---

```{r metathis, include = FALSE}
#Con esta libreria puedo poner informacion que saldra en el titulo, en los buscadores y demas, como de titulo y fechas. Asi como elegir la imagen que saldra de inicio.

library(metathis)
meta() %>%
  meta_name("github-repo" = "MiriamLL/Curso_CIAD") %>%
  meta_social(
    title = "Cargar datps",
    description = paste0(
      "Introduccion a RStudio",
      "Curso de R"),
    url = "https://github.com/MiriamLL/Curso_CIAD/blob/main/Clase3Parte1.html",
    image_alt = paste0(
      "Introduccion a R y RStudio",
      "Curso de R"),
    og_type = "website",
    og_author = "Miriam Lerma",
    twitter_card_type = "summary_large_image",
    twitter_creator = "@MiriamLL",
    twitter_site = "@MiriamLL")
```

```{r include = FALSE}
#Paquetes
library(xaringanExtra)
ColorLink<-"#219ebc"
ColorLinkInv<-"#f2cc8f"
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
``` 

```{r, echo=FALSE,include=FALSE, message=FALSE}
library(emo)
library(here)
library(fontawesome)
library(ggplot2)
```

class: title-slide, inverse, middle, right
background-image: url(https://images.unsplash.com/photo-1602264419088-8f8c7ab48489?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1267&q=80)
background-size: cover

### `r rmarkdown::metadata$title`
# `r rmarkdown::metadata$subtitle`

## `r rmarkdown::metadata$author`<br>
`r rmarkdown::metadata$date`

---

class: inverse

# Intro
- [Modelos mixtos](#lmer)
- [Incluir efectos aleatorios](#random_effects)
- [Incluir efectos anidados](#nested_effects)
- [AIC](#AIC)
- [Comparar modelos](#comparar)

--

#### Ustedes

- Conocimientos de R (saben abrirlo, cargar paquetes y datos, saben hacer operaciones y gr치ficos).  
- Quieren crear modelos mixtos en R y conocer la sintaxis.  
La clase de hoy esta en el [repositorio](https://github.com/MiriamLL/Prueba):
Clonen/Descarguen los materiales.  

#### Preguntas
Responder en el chat 游눫
- Han visto modelos mixtos en art칤culos o tesis?
- Alguien ha escuchado que es el AIC?

---
class: inverse

## Cr칠ditos & Recursos

Lecturas
- [`r fa("book-open", fill = ColorLinkInv)` Intro por Gabriela Hajduk](https://gkhajduk.github.io/2017-03-09-mixed-models/)
- [`r fa("book-open", fill = ColorLinkInv)` Introduccion por Athanasia Mowinckel](https://athanasiamo.github.io/LME_introduction_workshop/slides/lme_rladies_london.html#1)<br>
- [`r fa("book-open", fill = ColorLinkInv)` Lectura sobre mixed-models with R Michel Clark](https://m-clark.github.io/mixed-models-with-R/#)

Videos en espa침ol
- [`r fa("youtube", fill = ColorLinkInv)` Modelos mixtos por Alejandra Tapia](https://alejandraandrea.github.io/slides-xaringan-mixed-models/#1)<br>

En ingles  
- [`r fa("youtube", fill = ColorLinkInv)` Video explicando Teor칤a칌 Kyle Tomlinson](https://www.youtube.com/watch?v=sdYKtsmtXmc&list=PLVlVXU7jGfm1seY4xxINrsp23AmrYFYa7&index=4)


Imagenes
- Portada  
[Unsplash by Ilse Orsel](https://unsplash.com/@lgtts)  


---

name: repro
class: center, middle, inverse

# 1. Modelos lineares mixtos

---

## 1.1. Intro

Modelos lineales:  
- Errores aleatorios independientes
- Errores aleatorios siguen una distribuci칩n normal

Modelos lineales mixtos
- Incorpora efectos aleatorios para acomodar la correlaci칩n entre las observaciones 
- Condicionado a los efectos aleatorios, los errores aleatorios son independientes con  varianza constante 
- Errores aleatorios con distribuci칩n normal
- Efectos aleatorios con distribuci칩n normal 
- Efectos aleatorios y errores aleatorios son independientes 


---

## 1.1. Intro

쯇orque usarlos?

- Datos pueden presentar heterogeneidad
- Por ejemplo: pueden estar agrupados por provenir de diferentes 치reas, o presentar medidas repetidas
- Medidas repetidas induce a una estructura de correlaci칩n, que si no se considera puede llevar a estimaciones sesgadas
- Afectando las predicciones y por lo tanto las decisiones basadas en esos datos


---
name: lmer

## 1.2. Datos

Paquetes a cargar para leer los datos
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
library(here)
```

Cargar datos
```{r, message=FALSE}
url <- "https://raw.githubusercontent.com/alejandraandrea/slides-xaringan-mixed-models/master/dragons.tsv"
download.file(url, "dragons.tsv")
dragones <- read_tsv("dragons.tsv") #read_tsv de {readr}
```

---

## 1.2. Datos

Los datos contienen 480 observaciones contenidos en 4 columnas: testScore, bodyLenght, montainRange, site
```{r}
glimpse(dragones)
```

Antes de empezar cambiemos los nombres a espa침ol
```{r}
dragones<-dragones%>%
    rename(calificacion=testScore,
           tamanio = bodyLength,
           montania = mountainRange,
           sitio=site)
```

---

## 1.3. Preguntas

Imaginemos que:  
Se entrenaron dragones y se recopilaron datos de diferentes monta침as.

.center[<h1>游낼游눠</h1>]  

Entre mas r치pido aprendieron el entrenamiento mejor calificaci칩n, tambi칠n se midieron y se anoto en que sitio y en que regi칩n provienen.

.center[<h1>游쓇눮</h1>] 

쮸fectara el tama침o de los dragones a sus calificaciones?


---

## 1.4. Inspeccionar datos

Creemos un gr치fico de puntos
```{r,out.width="40%"}
dragones %>% 
  ggplot(aes(x=tamanio, 
             y=calificacion)) + 
             geom_jitter(alpha=.2)+
             theme_bw()
```


---

## 1.5 Ajustar modelo lineal

Cargar paquetes
```{r}
library(broom)
```

Ajustar un modelo lineal
```{r}
ajuste_lm <- lm(calificacion ~ tamanio, data=dragones)
```

Mirar estad칤sticos del modelo
```{r}
broom::tidy(ajuste_lm) %>% tibble::as_tibble()
```
쮼ntre m치s grandes, m치s inteligentes?

---

## 1.5 Ajustar modelo lineal

Informaci칩n sobre el modelo.
```{r}
glance(ajuste_lm) %>% 
  tibble::as_tibble()
```
Informaci칩n sobre el ajuste del modelo.
```{r}
info_ajuste_lm<-augment_columns(ajuste_lm, dragones)
info_ajuste_lm
```

---

## 1.5 Modelo lineal

Gr치fica el modelo lineal
```{r,out.width="40%"}
info_ajuste_lm %>% 
  ggplot(aes(x=tamanio,y=calificacion))+ 
  geom_jitter(alpha=.2)+
  geom_line(aes(x=tamanio,y=.fitted))+
  theme_bw()
```

---

## 1.6. Supuestos

Linealidad
```{r,out.width="40%"}
plot(ajuste_lm, which=1)
```

---

## 1.6. Supuestos
Normalidad
```{r,out.width="40%"}
plot(ajuste_lm, which=2)
```

---

## 1.6. Supuestos
Homocedasticidad
```{r,out.width="40%"}
plot(ajuste_lm, which=3)
```

---

## 1.7. Inspeccionar

Al graficar las monta침as por separado. 쯈ue notan?
```{r,out.width="40%"}
dragones %>%
  ggplot(aes(x=tamanio,y=calificacion, 
        colour=montania)) +
  geom_jitter(alpha=2) +
  theme_bw()
```

---

## 1.8. Inspeccionar

Separando por monta침as. 쯈ue notan?
```{r,out.width="30%"}
dragones %>% 
  ggplot(aes(tamanio,calificacion,
      colour = montania))+
  geom_jitter(alpha=2) + 
  facet_wrap(~ montania) +
  theme_bw()+
  theme(strip.background=element_rect(fill="white"))
```

---
name: random_effect

## 1.9. Efectos aleatorios

No se puede omitir la monta침a , 쯣ero como la incluimos?

- Como factor aleatorio.
- [`r fa("external-link-alt", fill = "#219ebc")` Que es un factor aleatorio y como saber cuando es aleatorio](https://dynamicecology.wordpress.com/2015/11/04/is-it-a-fixed-or-random-effect/)

Paquetes
```{r, message=FALSE, warning=FALSE}
library(broom.mixed)
library(lme4)
```

Sintaxis de los efectos aleatorios (random effects)
```{r}
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
```

---

## 1.9. Efectos aleatorios

Mirar nuestro nuevo modelo.
```{r}
tidy(ajuste_lmer) %>% tibble::as_tibble()
```
Mirar los ajustes del modelo.
```{r}
glance(ajuste_lmer) %>% tibble::as_tibble()
```

**No hay valor p 游눖游땴**

---

## 1.9. Valor p

La libreria lmerTest te puede dar un valor p, pero no es muy 칰til y adem치s no se reporta. 

```{r,message=FALSE, warning=FALSE}
library(lmerTest)
ajuste_lmer <- lmer(calificacion ~ tamanio + 
                      (1|montania), data = dragones)
tidy(ajuste_lmer) %>% tibble::as_tibble()
```

---

## 1.10. Efecto de la monta침a

Ver informaci칩n del ajuste: valores ajustados (.fitted), residuales (.resid)
```{r}
info_ajuste_lmer<- augment_columns(ajuste_lmer,dragones)
info_ajuste_lmer
```
Las monta침as parecen tener un efecto en la calificaci칩n.

---

## 1.10. Efecto de la monta침a

Veamos el efecto de las monta침as en la calificaci칩n.
```{r,out.width="30%"}
info_ajuste_lmer %>% 
 ggplot(aes(x=tamanio,y=calificacion, colour=montania))+ 
 geom_jitter(alpha=2)+ 
 facet_wrap(~ montania)+
 geom_line(aes(x=tamanio,y=.fitted),
 colour="black")+
theme_bw()
```

---

## 1.11. Supuestos

```{r,out.width="30%"}
plot(ajuste_lmer)
```

---

## 1.11. Supuestos

```{r,out.width="30%"}
qqnorm(resid(ajuste_lmer))
qqline(resid(ajuste_lmer))
```

---

## 1.11. Modelo mixto

Ver ajustes del modelo mixto que incluye **monta침as**
```{r,out.width="30%"}
summary(ajuste_lmer)
```

---

## 1.11. Modelo mixto

Se ve que la varianza de el sistema monta침oso es 339.7.
Entonces las monta침as son claramente importantes porque explican mucha de la variaci칩n. Como saber cuanto explican de la variaci칩n? Se puede tomar la varianza de la monta침a y dividirla por el total de la varianza. 

```{r}
339.7/(339.7 + 223.8)
```


---
name: AIC
class: title-slide,center, middle, inverse

# 2. AIC

---

## 2.1. AIC

El AIC (Akaike Information criterion) es un modelo matem치tico para evaluar que tan bien se ajusta el modelo a los datos generados. En estadistica se usa mucho para comparar modelos posibles y determinar cual es el mejor modelo.

AIC se calcula de:
- El numero de variables independientes que se us칩 para construir el modelo
- El estimado de m치xima verosimilitud (maximum likelihood), (que tan bien el modelo reproduce los datos)

El mejor modelo se identifica a partir de un AIC, que explica la mayor cantidad de variacion usando el menos numero de variables independientes. 

---

## 2.1. AIC

.center[<h1>游낼游눠</h1>]  

Usando el ejemplo de dragones, que modelo se ajusta mejor a nuestros datos?
A lo mejor colectamos variables que no son importantes para nuestro modelo.

Consideren: los AIC menores son mejores, y AIC penaliza los modelos que usen m치s par치metros.

---
name: nested_effects

## 2.1. Efectos aleatorios anidados

En nuestros datos de dragones.

La variable de sitio es un factor con tres niveles: un sitio a, b y c. Y existe un anidamiento (nesting) del sitio con la monta침a.  
Entonces los sitios no tienen significado si no le asignamos las monta침as. 

Para no tener que estar recordando que esto ocurre, lo mejor es crear una nueva variable anidada (nested)

```{r}
dragones$muestra <- factor(paste0(dragones$montania,
                                  dragones$sitio))
```

**Recordando** el factor aleatorio solo aparece en un nivel en particular.  
Por eso es anidado, cada sitio pertenece a un sistema monta침oso en especial y solo en ese sistema.  
Para efectos cruzados es cuando el factor aparece en m치s de un nivel en otros factores, por ejemplo si el mismo drag칩n aparece en m치s de un sistema monta침oso.

---

## 2.2. Factores aleatorios

De acuerdo a lo que vimos anteriormente, entonces no podemos poner los efectos aleatorios separados.
```{r}
modelo_incorrecto <- lmer(calificacion ~ tamanio + 
                      (1|montania) + (1|sitio), data = dragones)  
```
Este modelo trata los efectos aleatorios como cruzados.
**Recuerden** que depende de su modelo y muestreo cual elegir. 

---

## 2.3. Modelo completo

Con los datos de dragones, una manera de crear un modelo completo ser칤a la siguiente.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

```{r}
lmer_completo
```

---

## 2.4. Reportar el modelo

쮺omo se reporta eso?

De mejor a peor lo que podemos hacer es usar:

- Z-test de Wald 
- t-test de Wald (en este modelo los valores tendrian que estar balanceados)
- **Prueba de raz칩n de verosimilitud** (en ingl칠s: Likelihood ratio tests).  
Usando anova() o drop1())
- Markov chain Monte Carlo (MCMC) o un bootstramp parametrico con intervalos de confianza

---


## 2.5. Compara modelos

Modelo completo.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + 
                        (1|montania) + (1|muestra),
                      data = dragones, REML = FALSE)
```

Modelo reducido. **Nota** que este modelo no incluye tama침o.
```{r}
lmer_reducido <- lmer(calificacion ~ 1 + 
                        (1|montania) + (1|muestra), 
                      data = dragones, REML = FALSE)
```

Comparaci칩n de los modelos. 
```{r, eval=FALSE}
anova(lmer_reducido, lmer_completo) 
```

---

## 2.5. Compara modelos

Comparaci칩n de los modelos. Los modelos no son significativamente diferentes.   Tama침o no ayuda a explicar la calificaci칩n de los dragones.
```{r}
anova(lmer_reducido, lmer_completo)  
```

---

## 2.6. M치s factores

Si tuvieramos mayor cantidad de variables, el modelo se crear칤a de otra forma.

Intentemos incrementar la complejidad, al generar valores aleatorios
```{r}
set.seed(1234)
edad<-runif(480, min=0, max=100)
set.seed(1234)
fuego<-runif(480, min=0, max=15)
```

Agregar como variables
```{r}
dragones$edad<-edad
dragones$fuego<-fuego
```

Cargar paquetes
```{r}
library(lme4)
library(MuMIn)
```

---

## 2.8. Comparar muchos modelos

Una manera de comprar modelos cuando tenemos muchas variables es crear varios modelos.

Primer modelo
```{r}
mod1 <- lmer(calificacion ~ tamanio + (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

Segundo modelo
```{r}
mod2 <- lmer(calificacion ~ tamanio + fuego + (1|montania) + (1|muestra), 
					     data = dragones, REML = FALSE)
```

Tercer modelo
```{r}
mod3 <- lmer(calificacion ~ tamanio + fuego + edad + (1|montania) + (1|muestra),data = dragones, REML = FALSE)
```

---

## 2.7. drop1

Otra manera de comparar modelos es usando **drop1**

Hay que crear el modelo completo.
```{r}
lmer_completo <- lmer(calificacion ~ tamanio + edad + fuego +
                        (1|montania) + (1|muestra), 
				  data = dragones, REML = FALSE)
```

Esta funci칩n te sugiere como reducir tu modelo.
```{r}
drop1(lmer_completo, test="F")
```

---

## 2.9. Comparar muchos modelos

Otra manera es generar un modelo completo y usar la funci칩n **dredge**.  
Esta funci칩n sirve para evaluar que factores se pueden sacar del modelo para simplificarlo.

```{r}
library(MuMIn)
options(na.action = "na.fail")
```

```{r}
lmer_completo <- lmer(calificacion ~ tamanio +
                        (1|montania) + (1|muestra), 
                      data = dragones, REML = FALSE)
```

```{r, eval=FALSE}
dredge(lmer_completo)
```

---

## 2.9. Comparar muchos modelos

- **AICc**: Valores AIC para muestras peque침as
- **delta**: diferencia entre modelos. Por convenci칩n AIC<2 se consideran modelos posibles.
-**weight**: Peso del modelo.

Todos estos valores pueden reportarse.

```{r}
dredge(lmer_completo)
```

---

# 3. Para considerar

- [Usar Machine learning](https://github.com/m-clark/introduction-to-machine-learning)

- [Usar estadistica bayesiana](https://oliviergimenez.github.io/blog/bayesworkshop/)

Otras lecturas:
- [El reinado de los valores p se ha terminado, ahora que hacemos?](https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174)


---

class: left, inverse

# Contacto

Recapitulando

- [Modelos mixtos](#lmer)
- [Incluir efectos aleatorios](#random_effects)
- [Incluir efectos anidados](#nested_effects)
- [AIC](#AIC)
- [Comparar modelos](#comparar)
<br>
<br>

Para dudas, comentarios y sugerencias:  
- Escr칤beme a miriamjlerma@gmail.com

<br>
<br>

.right[Este material esta accesible y se encuentra en <br>
mi [`r fa("external-link-alt", fill = ColorLinkInv)`github](https://github.com/MiriamLL/Curso_CIAD/)
y mi [`r fa("external-link-alt", fill = ColorLinkInv)`p치gina](https://www.miriam-lerma.com/posts/2021-03-01-introar/)


.center[
```{r, echo=FALSE}
library(fontawesome)
```
<h3>`r fa("home", fill = ColorLinkInv)`[Volver ](https://www.miriam-lerma.com/posts/2021-03-01-introar/)
]]

